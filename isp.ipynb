{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Stratified Inference: ESI\n",
    "\n",
    "Conservative and exact tests and confidence bounds for the population total (or mean) of a binary population from a stratified simple random sample.\n",
    "\n",
    "Wendell and Schmee (1996, https://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476950) proposed making inferences about the population total by maximizing a $P$-value over a set of nuisance parameters---the individual stratum totals.\n",
    "They find the $P$-value by ordering possible outcomes based on the estimated population proportion: \n",
    "the test statistic is the \"tail probability\" of $\\hat{p}$, the unbiased\n",
    "estimator of the population percentage from the stratified sample.\n",
    "They construct confidence bounds by inverting hypothesis tests.\n",
    "\n",
    "Wendell and Schmee also provided R scripts for searching for the maximum over \n",
    "the allocations; the scripts became computationally impractical for more than three strata.\n",
    "\n",
    "Maximizing the $P$-value over all allocations of $G$ ones\n",
    "across $S$ strata\n",
    "is combinatorially complex: Feller's \"bars and stars\" argument shows that there are $\\binom{G+S-1}{S-1}$ ways to allocate $G$ objects among $S$ strata.\n",
    "(Some of those can be ruled out, for instance if $G$ exceeds the size of any stratum.)\n",
    "For $S=10$ strata of size $N_s = 400$ and $G = 300$, \n",
    "there are roughly 6.3e+16 allocations: impractical by any standard.\n",
    "\n",
    "This document replicates the Wendell & Schmee method in python\n",
    "and introduces a different conservative strategy for stratified inference, \n",
    "also based on maximizing\n",
    "the $P$-value over the nuisance parameters.\n",
    "\n",
    "The test statistic Wendell & Schmee use is sensible, but only one of infinitely many.\n",
    "The new method uses a different test statistic: Fisher's combining function applied\n",
    "to the tail probabilities of individual hypergeometric counts.\n",
    "A naive approach to maximizing this $P$-value over the nuisance parameters \n",
    "would also involve a search over\n",
    "a combinatorial number of possible allocations.\n",
    "However,\n",
    "\n",
    "1. No combinatorial search is necessary: an allocation that yields the largest\n",
    "$P$-values and corresponding confidence bounds can be constructed by a simple\n",
    "algorithm in order $N \\log N$ operations, where $N$ is the number of items in the population. \n",
    "Runtime can be reduced further to $O( N \\log S )$. \n",
    "The number of strata has little effect on the complexity of the calculation.\n",
    "2. The resulting tests and confidence intervals are in some cases sharper than those of\n",
    "Wendell and Schmee, in particular when the strata are heterogeneous--which is often the justification for drawing a stratified sample in the first place.\n",
    "\n",
    "The code below implements Wright's method; the brute-force approach (enumerate all ways of allocating a given number of ones across the strata, find the maximum $P$-value across those allocations); the new, more efficient approach, which exploits special structure of the problem; and the Wendell & Schmee approach. \n",
    "\n",
    "It replicates a number of calculations in the Wendell & Schmee paper.\n",
    "Several algorithms for finding confidence intervals are implemented, including a line \n",
    "search, a bisection-like method that takes advantage of the fact that the\n",
    "possible values are integers, and a fast constructive algorithm for the new method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "A population of $N$ items of which $G$ are labeled \"1\" and $N-G$ are labeled \"0\"\n",
    "is allocationed into $S$ strata.\n",
    "Stratum $s$ contains $N_s$ items, of which $G_s$ are labeled \"1.\"\n",
    "Thus $N = \\sum_{s=1}^S N_s$ and $G := \\sum_{s=1}^S G_s$.\n",
    "We draw a simple random sample of size $n_s$ from stratum $s$, independently across strata.\n",
    "(I.e., from stratum $s$ we draw a sample of size $n_s$ in such a way \n",
    "that every subset of $n_s$ distinct items of the $N_s$ items is equally likely;\n",
    "and the $S$ samples are drawn independently.)\n",
    "\n",
    "Let $Y_s$ denote the number of items labeled \"1\" in the sample from stratum $s$.\n",
    "The variables $\\{Y_s \\}_{s=1}^S$ are independent.\n",
    "The observed value of $Y_s$ is $y_s$.\n",
    "\n",
    "We seek hypothesis tests and confidence bounds for $G$.\n",
    "We first consider one-sided tests of the hypothesis $G = g$ against the \n",
    "alternative $G > g$, and\n",
    "corresponding lower confidence bounds for $G$;\n",
    "reversing the roles of \"0\" and \"1\" gives upper confidence \n",
    "bounds, _mutatis mutandis_.\n",
    "\n",
    "The general strategy for testing the hypothesis $G=g$ is to \n",
    "find the largest $P$-value among all ways of allocating $g$ \n",
    "items labeled \"1\" among the $S$ strata \n",
    "(honoring the stratum sizes $\\{N_s\\}$).\n",
    "That is a $P$-value for the composite hypothesis $G=g$.\n",
    "The maximum can be found by examining all such allocations and\n",
    "calculating the $P$-value for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wright's Method: Sum of Šidák Intervals\n",
    "\n",
    "One easy way to get a lower confidence bound for the sum is to take the sum of\n",
    "simultaneous lower confidence bounds for each stratum.\n",
    "Because the samples from different strata are independent, Šidák's adjustment works.\n",
    "Wright (1991) suggests this approach.\n",
    "\n",
    "A confidence bound for $G_s$ can be constructed from $Y$ by inverting hypergeometric tests.\n",
    "\n",
    "To have joint confidence level $1-\\alpha$, make each confidence interval at $(1-\\alpha)^{1/S}$.\n",
    "\n",
    "This is an example of a much more general approach: make a joint $1-\\alpha$ confidence set for all the parameters $\\{G_j\\}_{j=1}^S$, then find a lower bound on a functional of interest (here, their sum) over the joint set. Whenever the joint confidence set covers the parameter, the lower bound does not exceed the true value of the functional of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wendell-Schmee Test\n",
    "\n",
    "The test statistic for the Wendell-Schmee test is the unbiased estimate\n",
    "of the population proportion, $G/N$:\n",
    "\n",
    "$$\n",
    "  \\hat{p} := \\frac{1}{N} \\sum_{s=1}^S N_s y_s/n_s.\n",
    "$$\n",
    "The $P$-value of the hypothesis $G_s=g_s$, $s=1, \\ldots, S$, \n",
    "is the \"lower tail probability\" of $\\hat{p}$.\n",
    "\n",
    "Wendell and Schmee consider maximizing this lower tail probability over all allocations\n",
    "of $g$ ones across strata, either by exhaustive search, or by numerical optimization\n",
    "using a descent method from some number of random starting points.\n",
    "(They show graphically that the tail probability is not convex in the original\n",
    "parametrization.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructive maximization\n",
    "\n",
    "For some test statistics, there is a much more efficient approach, developed here.\n",
    "\n",
    "Define \n",
    "$$\n",
    "   p_s(g_s) := \\Pr \\{ Y_s \\ge y_s || G_s = g_s \\} =\n",
    "   \\sum_{y = y_s}^{g_s} \\frac{\\binom{g_s}{y} \\binom{N_s-g_s}{n_s - y}}{\\binom{N_s}{n_s}},\n",
    "$$\n",
    "where $\\binom{a}{b} := 0$ if $a \\le 0$ or $b > a$.\n",
    "(The double vertical bars denote \"computed on the assumption that.\")\n",
    "This upper tail probability is a $P$-value for the most powerful family of tests of the\n",
    "hypothesis $G_s = g_s$ against the alternative $G_s > g_s$.\n",
    "\n",
    "A test of the conjunction hypothesis $G_s = g_s$, $s=1, \\ldots, S$ can be constructed\n",
    "using Fisher's combining function:\n",
    "if all $S$ hypotheses are true, the distribution of\n",
    "$$\n",
    "  X^2(\\vec{g}) := -2 \\sum_{s=1}^S \\log p_s(g_s)\n",
    "$$\n",
    "is dominated by the chi-square distribution with $2S$ degrees of freedom.\n",
    "Let $\\chi_d(z)$ denote the chance that a random variable with the chi-square \n",
    "distribution with $d$ degrees of freedom is greater than or equal to $z$.\n",
    "Then a conservative $P$-value for the allocation $\\vec{g}$ is\n",
    "$$\n",
    "   P(\\vec{g}) = \\chi_{2S}(X^2(\\vec{g})).\n",
    "$$\n",
    "The allocation $\\vec{g}$ of $g$ ones across strata that maximizes the $P$-value\n",
    "is the allocation that minimizes $X^2(\\vec{g})$ and satisfies $\\sum_s g_s = g$.\n",
    "Equivalently, it is the allocation that maximizes $\\sum_{s=1}^S \\log p_s(g_s)$.\n",
    "\n",
    "Let \n",
    "$$\n",
    "   a_s(j) := \\left \\{ \n",
    "                 \\begin{array}{ll} \n",
    "          \\log p_s(y_s), & j = y_s \\\\\n",
    "          \\log \\left (p_s(j)/p_s(j-1) \\right ), & j = y_s+1, \\ldots N_s-(n_s-y_s).\n",
    "                 \\end{array}\n",
    "                 \\right .\n",
    "$$\n",
    "\n",
    "Then $\\log p_s(g_s) = \\sum_{j=y_s}^{g_s} a_s(j)$ if \n",
    "$y_s \\le g_s \\le N-(n_s-y_s)$, and \n",
    "$\\log p_s(g_s) = -\\infty$ otherwise.\n",
    "Moreover, \n",
    "$$\n",
    "  X^2(\\vec{g}) =  -2\\sum_{s=1}^S a_s(y_s) -2\\sum_{s=1}^S \\sum_{j=y_s+1}^{g_s} a_s(j)\n",
    "$$\n",
    "provided $y_s \\le g_s \\le N-(n_s-y_s)$, $s=1, \\ldots, S$; otherwise, it is infinite.\n",
    "\n",
    "An allocation of $g$ ones across strata is inconsistent with the data unless\n",
    "$g_s \\ge y_s$, $s=1, \\ldots, S$.\n",
    "Thus, in considering how to allocate $g$ ones to maximize the $P$-value, \n",
    "the first sum above, accounting for $\\sum_s y_s$ ones, is \"mandatory,\" or the $P$-value will be zero.\n",
    "The question is how to allocate the remaining $g - \\sum_s y_s$ ones to maximize\n",
    "the $P$-value (equivalently, to minimize $X^2(\\vec{g})$).\n",
    "\n",
    "Let $b_k$ denote the $k$th largest element of the set \n",
    "\n",
    "$$\n",
    "   \\{a_s(j): j=y_s+1, \\ldots, N_s-(n_s-y_s), \\;\\; s=1, \\ldots, S \\},\n",
    "$$\n",
    "with ties broken arbitrarily.\n",
    "Define $\\tilde{g}_y := g - \\sum_{s=1}^S y_s$.\n",
    "\n",
    "**Proposition.** For every $\\vec{g}$ with $\\sum_s g_s = g$, \n",
    "$$\n",
    "X^2(\\vec{g}) \\ge X_*^2(g) := \\left \\{ \\begin{array}{ll}\n",
    "    -2 \\left ( \\sum_{s=1}^S a_s(y_s) + \\sum_{k=1}^{\\tilde{g}_y} b_k \n",
    "                \\right ), & \\sum_s y_s \\le g \\le N - \\sum_s (n_s-y_s) \\\\\n",
    "    \\infty, & \\mbox{ otherwise. }\n",
    "    \\end{array}\n",
    "    \\right . \n",
    "$$\n",
    "\n",
    "**Proof.** Any $\\vec{g}$ for which $X^2(\\vec{g})$ is finite includes the first sum\n",
    "and a sum of $\\tilde{g}_y$ elements of $\\{b_k\\}$; the latter is at most the sum of the\n",
    "$\\tilde{g}_y$ largest elements of $\\{b_k\\}$. $\\Box$\n",
    "\n",
    "Moreover, the bound is sharp, because $a_s(j)$ decrease monotonically with $j$ for\n",
    "$j = y_s+1, \\ldots, N_s-(n_s-y_s)$.\n",
    "Thus, if $a_s(i)$ is a term in the second sum for some $i > y_s+1$, so \n",
    "is every $a_s(j)$, $y_s \\le j \\le i-1$: the second sum indeed corresponds \n",
    "to a particular allocation \n",
    "$\\vec{g}$ of $g$ ones across the $S$ strata, with $y_s \\le g_s \\le N_s-(n_s-y_s)$.\n",
    "Among all allocations of $g$ items labeled \"1,\" this one minimizes has the smallest tail \n",
    "probability, because it corresponds to the exponentiation of the smallest sum of logs \n",
    "(the largest negative sum of logs). $\\Box$\n",
    "\n",
    "\n",
    "**Proposition:** For $j \\in y_s+1, \\ldots, N_s-(n_s-y_s)$, $a_s(j)$ is monotone \n",
    "decreasing in $j$.\n",
    "\n",
    "**Theorem:** If $\\sum_s y_s \\le g \\le N - \\sum_s (n_s-y_s)$, \n",
    "\n",
    "$$\n",
    "P(g) \\le \\chi_d(X_*^2(g)).\n",
    "$$\n",
    "\n",
    "**Proof:**\n",
    "Immediate from the definitions.\n",
    "\n",
    "The theorem shows that a \"greedy\" approach finds a conservative $P$-value:\n",
    "Construct the values $a_s(j)$ and the set $\\{b_k\\}$. \n",
    "Add the $S$ values $\\{a_s(x_k)$ to the $g-g_y$ largest elements of $\\{b_k\\}$ and \n",
    "multiply the sum by $-2$.\n",
    "The upper tail probability of the chi-square distribution with $2S$ degrees of \n",
    "freedom is a conservative $P$-value for the hypothesis $G=g$.\n",
    "\n",
    "A conservative upper $1-\\alpha$ confidence bound for $G$ is the largest $g$ for which \n",
    "$P(g) \\ge \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the direction of the test\n",
    "\n",
    "The test of the hypothesis $G=g$ given above is a one-sided test against the alternative \n",
    "$G > g$: it rejects if the chance of observing \"so few\" good objects is small.\n",
    "\n",
    "To test against the alternative $G < g$ (i.e., to reject if the chance of observing \"so many\"\n",
    "good objects is small), exchange the role of \"good\" and \"bad.\"\n",
    "The hypothesis $G < g$ is equivalent to the hypothesis $(N-G) > (N-g)$.\n",
    "\n",
    "The resulting null hypothesis is $G = N-g$, and the data are $n_s - Y_s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with replacement\n",
    "\n",
    "The same approaches work for sampling with replacement.\n",
    "\n",
    "For simplicity, assume that the population proportion $\\pi = G/N$ and the stratum proportions $\\pi_s G_s/N_s$ can be any numbers between $0$ and $1$, not just multiples of $1/N$ or $1/N_s$.\n",
    "\n",
    "We observe $Y_s \\sim \\mathrm{Bin}(n_s, \\pi_s)$, $s = 1, \\ldots, S$.\n",
    "The observations are independent.\n",
    "The population proportion is $\\pi := G/N = N^{-1}\\sum_s \\pi_s n_s$.\n",
    "\n",
    "Define \n",
    "$$\n",
    "   p_s(\\mu_s) := \\Pr \\{ Y_s \\ge y_s || \\pi_s = \\mu_s \\} =\n",
    "   \\sum_{y = y_s}^{n_s} \\binom{n_s}{y} \\mu_s^y (1-\\mu_s)^{n_s-y}.\n",
    "$$\n",
    "This is the $P$-value of the hypothesis $\\pi_s = \\mu_s$ tested against the\n",
    "alternative $\\pi_s > \\mu_s$.\n",
    "\n",
    "A test of the conjunction hypothesis $\\pi_s = \\mu_s$, $s=1, \\ldots, S$ can be constructed\n",
    "using Fisher's combining function:\n",
    "Let $g_s = N_s\\mu_s$, $s = 1, \\ldots, S$.\n",
    "If all $S$ hypotheses are true, the distribution of\n",
    "$$\n",
    "  X^2(\\vec{g}) := -2 \\sum_{s=1}^S \\log p_s(\\mu_s)\n",
    "$$\n",
    "is dominated by the chi-square distribution with $2S$ degrees of freedom.\n",
    "Let $\\chi_d(z)$ denote the survival function for the chi-sqare distribution with $d$ degrees\n",
    "of freedom, i.e., the chance that a random variable with the chi-square \n",
    "distribution with $d$ degrees of freedom is greater than or equal to $z$.\n",
    "Then a conservative $P$-value for the allocation $\\vec{g}$ is\n",
    "$$\n",
    "   P(\\vec{g}) = \\chi_{2S}(X^2(\\vec{\\mu})).\n",
    "$$\n",
    "The allocation $\\vec{\\mu}$ that maximizes the $P$-value\n",
    "is the allocation that minimizes $X^2(\\vec{g})$ and satisfies $\\sum_s \\mu_s = g$.\n",
    "Equivalently, it is the allocation that maximizes $\\sum_{s=1}^S \\log p_s(g_s)$.\n",
    "\n",
    "Does a greey approach work here?\n",
    "\n",
    "**Lemma.** The Binomial pdf is log concave in $p$.\n",
    "\n",
    "**Proof.** \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d^2}{dp^2} \\log \\left [ \\binom{n}{k}p^k(1-p)^{n-k} \\right ] & = \\frac{d^2}{dp^2} \\left [ C + k\\log p + (n-k)\\log(1-p) \\right ] \\\\\n",
    "&= \\frac{d}{dp} (k/p - (n-k)/(1-p)) \\\\\n",
    "&= -k/p^2 - (n-k)/(1-p)^2 < 0. \\Box\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open questions\n",
    "\n",
    "The Wendell-Schmee test coincides exactly with the unadjusted new test (i.e., \n",
    "using the joint probability _without_ calibrating it with Fisher's combining function)\n",
    "for small observed counts. The optimal parameter values\n",
    "are identical, and the Wendell-Schmee $P$-value is equal to the tail probability in the new test\n",
    "before Fisher's adjustment. \n",
    "Why?\n",
    "\n",
    "For what observations is the optimal allocation the same for the two tests?\n",
    "\n",
    "Can a similar constructive/greedy\n",
    "approach find the optimizer (or a bound) for the Wendell-Schmee test?\n",
    "(Implausible because of the lack of convexity, at least in the original parametrization.)\n",
    "\n",
    "What is the empirical coverage of the two methods?\n",
    "What's the worst-case?\n",
    "\n",
    "When is the new method sharper than Wendell-Schmee? (Seems to be when the strata\n",
    "are heterogeneous.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install permute and cryptorandom in the current kernel if needed\n",
    "import sys\n",
    "!{sys.executable} -m pip install permute --user\n",
    "!{sys.executable} -m pip install cryptorandom --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import binom, hypergeom, chi2\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "from permute.utils import binom_conf_interval, hypergeom_conf_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New utility functions\n",
    "\n",
    "def fisher_log(log_p, **kwargs):\n",
    "    '''\n",
    "    Fisher's combining function for the log of independent P-values\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    log_p : np.array or float\n",
    "        vector of logarithms of independent P-values or sum of the logs\n",
    "    df : int\n",
    "        twice the number of log P-values in the sum. \n",
    "        Required if log_p is a scalar; otherwise, inferred from len(log_p)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    P : float\n",
    "        combined P-value (not on a log scale)\n",
    "    '''\n",
    "    if not isinstance(log_p, (list, tuple, np.ndarray)):  # log_p is already the sum; need sensible df\n",
    "        df = kwargs.get('df',0)\n",
    "        assert df >= 2, f'{df=} incorrect or not set'\n",
    "    else: # there's a vector of log P-values; df is twice its length\n",
    "        df = 2*len(log_p)\n",
    "    return sp.stats.chi2.sf(-2*np.sum(log_p), df=df)\n",
    "\n",
    "def bars_stars(strata, found, good):\n",
    "    '''\n",
    "    Generate all allocations of `good` 1s across the strata\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    found : list of ints\n",
    "        number of 1s found in the sampl from each stratum\n",
    "    good : int\n",
    "        number of 1s to distribute across the strata\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    generator that iterates over all allocations\n",
    "    '''\n",
    "    n_strata = len(strata)\n",
    "    barsNstars = good + n_strata\n",
    "    bars = [0]*n_strata + [barsNstars]\n",
    "    return ([bars[j+1] - bars[j] - 1 for j in range(n_strata)]\n",
    "            for bars[1:-1] in itertools.combinations(range(1, barsNstars), n_strata-1)\n",
    "            if all(((bars[j+1] - bars[j] - 1 <= strata[j]) and \\\n",
    "            (bars[j+1] - bars[j] -1 >= found[j])) for j in range(n_strata)))            \n",
    "\n",
    "\n",
    "class StratifiedBinary:\n",
    "    '''\n",
    "    allocation of 1s to strata\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    strata : numpy array of ints\n",
    "        stratum sizes\n",
    "    sams : numpy array of ints\n",
    "        sample sizes\n",
    "    found : numpy array of ints\n",
    "        number of 1s in the sample from each stratum\n",
    "    alloc : numpy array of ints\n",
    "        initial allocation of 1s to strata (found)\n",
    "    log_p : numpy array of floats\n",
    "        tail probabilities for the allocation\n",
    "    next_up : numpy array of floats\n",
    "        log of the probability multipliers for including an additional 1 in each stratum\n",
    "'''\n",
    "    \n",
    "    def __init__(self, strata=None, sams=None, found=None, alloc=None, log_p=None, next_up=None):\n",
    "        self.strata = strata\n",
    "        self.sams = sams\n",
    "        self.found = found\n",
    "        self.alloc = alloc\n",
    "        self.log_p = log_p\n",
    "        self.next_up = next_up\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{strata=}\\n{sams=}\\n{found=}\\n{alloc=}\\n{log_p=}\\n{next_up=}'        \n",
    "    \n",
    "    def allocate_first(self):\n",
    "        '''\n",
    "        initialize the allocation of 1s to strata and ingredients for constructive max\n",
    "        '''\n",
    "        self.alloc = self.found.copy()                    # allocation that maximizes the P-value so far\n",
    "        self.log_p = np.array([sp.stats.hypergeom.logsf(self.found[s]-1, self.strata[s], self.alloc[s], \\\n",
    "                             self.sams[s]) for s in range(len(self.strata))])  # stratumwise log tail probabilities\n",
    "        self.next_up = np.array([np.NINF if self.alloc[s]+1 > self.strata[s]-self.sams[s]+self.found[s] \\\n",
    "                                 else sp.stats.hypergeom.logsf(self.found[s]-1, self.strata[s], self.alloc[s]+1,\\\n",
    "                                self.sams[s]) - self.log_p[s] for s in range(len(self.strata))])\n",
    "        return True\n",
    "\n",
    "    def allocate_next(self):\n",
    "        '''\n",
    "        allocate an additional 1 to the stratum that gives largest tail probability\n",
    "\n",
    "        updates alloc and next_up in place\n",
    "        '''\n",
    "        big = np.argmax(self.next_up)\n",
    "        self.alloc[big] += 1\n",
    "        self.log_p[big] = sp.stats.hypergeom.logsf(self.found[big]-1, self.strata[big], self.alloc[big], self.sams[big])\n",
    "        self.next_up[big] = (np.NINF if self.alloc[big]+1 > self.strata[big]-self.sams[big]+self.found[big]\n",
    "                             else sp.stats.hypergeom.logsf(self.found[big]-1, self.strata[big], self.alloc[big]+1, \n",
    "                             self.sams[big]) - self.log_p[big])\n",
    "        return (True if np.max(self.next_up) > np.NINF else False)\n",
    "    \n",
    "    def fisher_p(self):\n",
    "        '''\n",
    "        Fisher P-value\n",
    "        '''\n",
    "        return fisher_log(self.log_p)\n",
    "    \n",
    "    def total(self):\n",
    "        '''\n",
    "        total 1s allocated\n",
    "        '''\n",
    "        return np.sum(self.alloc)\n",
    "    \n",
    "    def n_strata(self):\n",
    "        '''\n",
    "        number of strata\n",
    "        '''\n",
    "        return len(self.strata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum P-values over allocations \n",
    "            \n",
    "def strat_test_brute(strata, sams, found, good, **kwargs):\n",
    "    '''\n",
    "    p-value of the hypothesis that the number of 1s in a binary population is \n",
    "    less than or equal to `good`, from a stratified random sample.\n",
    "    \n",
    "    Assumes that a simple random sample of size sams[s] was drawn from stratum s, \n",
    "    which contains strata[s] objects in all.\n",
    "    \n",
    "    The P-value is the maximum Fisher combined P-value across strata\n",
    "    over all allocations of good 1s among the strata. The allocations are\n",
    "    enumerated using Feller's \"bars and stars\" construction, constrained to honor the\n",
    "    stratum sizes and the data (each stratum can contain no more 1s than it has items in all\n",
    "    minus the observed number of 0s, nor fewer \"good\" items than the sample contains).\n",
    "    \n",
    "    The number of allocations grows combinatorially: there can be as many as\n",
    "    [(#strata + #1s) choose (#strata-1)] allocations, making the brute-force approach computationally \n",
    "    infeasible when the number of strata and/or the number of 1s is large.\n",
    "    \n",
    "    The test is a union-intersection test: the null hypothesis is the union over allocations\n",
    "    of the intersection across strata of the hypothesis that the number of 1s\n",
    "    in the stratum is less than or equal to a constant.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strata : list of ints\n",
    "        sizes of the strata\n",
    "    sams : list of ints\n",
    "        sample sizes from the strata\n",
    "    found : list of ints\n",
    "        the numbers of 1s found in the samples from the strata\n",
    "    good : int\n",
    "        the hypothesized total number of 1s in the population\n",
    "    kwargs : keyword arguments for this function and the functions it calls\n",
    "        alternative : string {'lower', 'upper'}\n",
    "            test against the alternative that the true number of 1s is less than good (lower)\n",
    "            or greater than good ('upper'). Default 'lower'\n",
    "        combining_function : callable \n",
    "            combining function; default is fisher_log. \n",
    "            kwarg is also passed to combining_function\n",
    "        cheap_combiner : callable\n",
    "            monotone increasing function of the combining function. \n",
    "            Default np.sum if combining_function == fisher_log\n",
    "            kwarg also passed to cheap_combiner\n",
    "        warn : int\n",
    "            warn if the number of allocations exceeds this. Default 10**7        \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p : float\n",
    "        maximum combined p-value over all ways of allocating good \"good\" objects\n",
    "        among the strata, honoring the stratum sizes.        \n",
    "    alloc : list\n",
    "        an allocation that attains the maximum p-value\n",
    "    '''\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower','upper'], f'alternative {alternative} not implemented'\n",
    "    alloc = None\n",
    "    sams = np.array(sams, dtype=int)\n",
    "    found = np.array(found, dtype=int)\n",
    "    strata = np.array(strata, dtype=int)\n",
    "    if good < np.sum(found):     \n",
    "        p = 0 if alternative == 'lower' else 1 \n",
    "    elif good > np.sum(strata) - np.sum(sams) + np.sum(found):\n",
    "        p = 1 if alternative == 'lower' else 0\n",
    "    else:  \n",
    "        if alternative == 'upper':                   # exchange roles of 1s and 0s\n",
    "            compl = sams - found                     # 0s found \n",
    "            bad = np.sum(strata) - good              # total 0s hypothesized\n",
    "            kwargs_c = kwargs.copy()\n",
    "            kwargs_c['alternative'] = 'lower'\n",
    "            p, alloc_c = strat_test_brute(strata, sams, compl, bad, **kwargs_c)\n",
    "            alloc = None if alloc_c is None else list(strata-np.array(alloc_c, dtype=int))\n",
    "        else:\n",
    "            p = np.NINF   # initial value for the max\n",
    "            n_strata = len(strata)\n",
    "            parts = sp.special.binom(good+n_strata-1, n_strata-1)\n",
    "            combining_function = kwargs.get('combining_function', fisher_log)\n",
    "            if combining_function == fisher_log:\n",
    "                kwargs['df'] = 2*n_strata\n",
    "                cheap_combiner = lambda p_vec, **kwargs: np.sum(p_vec)\n",
    "            else:\n",
    "                cheap_combiner = kwargs.get('cheap_combiner', combining_function)\n",
    "            warn = kwargs.get('warn',10**7)\n",
    "            if parts >= warn:\n",
    "                print(f'warning--large number of allocations: {parts}')\n",
    "            alloc = found.copy()\n",
    "            for part in bars_stars(strata, found, good):\n",
    "                p_new = cheap_combiner( \n",
    "                            np.array([sp.stats.hypergeom.logsf(found[s]-1, strata[s], part[s], sams[s])\n",
    "                            for s in range(n_strata)]),\n",
    "                            **kwargs)\n",
    "                if p_new > p:\n",
    "                    alloc = part\n",
    "                    p = p_new\n",
    "            p = combining_function(p, **kwargs)\n",
    "    return p, (None if alloc is None else list(alloc))\n",
    "    \n",
    "def strat_test(strata, sams, found, good, **kwargs):\n",
    "    \"\"\"\n",
    "    P-value for the hypothesis that the number of 1s in a binary population is not \n",
    "    greater than (or not less than) a hypothesized value, based on a stratified \n",
    "    random sample without replacement.\n",
    "    \n",
    "    Uses the fast algorithm to find the P-value constructively.\n",
    "    \n",
    "    Uses Fisher's combining function to combine stratum-level P-values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes in the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    good : int\n",
    "        hypothesized number of ones in the population\n",
    "    kwargs : dict\n",
    "        alternative : string {'lower', 'upper'} default 'lower'\n",
    "            test against the alternative that the true number of 1s is less than (lower) \n",
    "            or greater than (upper) the hypothesized number, good\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p : float\n",
    "        P-value\n",
    "    alloc : list\n",
    "        an allocation that attains the maximum p-value\n",
    "    \"\"\"\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower', 'upper'], f'alternative {alternative} not implemented'\n",
    "    strata = np.array(strata, dtype=int)\n",
    "    sams = np.array(sams, dtype=int)\n",
    "    found = np.array(found, dtype=int)\n",
    "    good = int(good)\n",
    "    alloc = None\n",
    "    if good < np.sum(found):     \n",
    "        p = 0 if alternative == 'lower' else 1 \n",
    "    elif good > np.sum(strata) - np.sum(sams) + np.sum(found):\n",
    "        p = 1 if alternative == 'lower' else 0\n",
    "    else:\n",
    "        if alternative == 'upper':                  # exchange roles of \"good\" and \"bad\"\n",
    "            compl = sams - found                    # bad items found \n",
    "            bad = np.sum(strata) - good             # total bad items hypothesized\n",
    "            kwargs_c = kwargs.copy()\n",
    "            kwargs_c['alternative'] = 'lower'\n",
    "            p, alloc_c = strat_test(strata, sams, compl, bad, **kwargs_c)\n",
    "            alloc = (None if alloc_c is None \n",
    "                          else list(strata-np.array(alloc_c, dtype=int)))\n",
    "        else:  \n",
    "            if good < np.sum(found) or good > np.sum(strata - sams + found): # impossible\n",
    "                p = 0  \n",
    "            elif good == np.sum(strata-sams+found): # the \"packed\" allocation guarantees this outcome or more 1s\n",
    "                p = 1\n",
    "                alloc = strata-sams+found      \n",
    "            else:                                   # outcome is possible but not certain under the composite null \n",
    "                optimal = StratifiedBinary(strata=strata, sams=sams, found=found)\n",
    "                optimal.allocate_first()\n",
    "                while optimal.total() < good:\n",
    "                    optimal.allocate_next()\n",
    "                p = optimal.fisher_p()\n",
    "                alloc = optimal.alloc\n",
    "    return p, (None if alloc is None else list(alloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals\n",
    "\n",
    "def strat_ci_bisect(strata, sams, found, **kwargs):\n",
    "    \"\"\"\n",
    "    Confidence bound on the number of ones in a stratified binary population,\n",
    "    based on a stratified random sample without replacement\n",
    "    \n",
    "    If alternative=='lower', finds an upper confidence bound.\n",
    "    If alternative=='upper', finds a lower confidence bound.\n",
    "\n",
    "    Uses an integer bisection search to find an exact confidence bound.\n",
    "    The starting upper endpoint for the search is the unbiased estimate\n",
    "    of the number of ones in the population. That could be refined in various\n",
    "    ways to improve efficiency.\n",
    "    \n",
    "    The lower endpoint for the search is the Šidák joint lower confidence bounds,\n",
    "    which should be more conservative than the exact bound.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes in the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    kwargs:\n",
    "        alternative : string in {'lower', 'upper'}\n",
    "            if alternative=='lower', finds an upper confidence bound.\n",
    "            if alternative=='upper', finds a lower confidence bound.\n",
    "            While this is not mnemonic, it corresponds to the sidedness of the tests\n",
    "            that are inverted to get the confidence bound.\n",
    "        cl : float\n",
    "            confidence level. Assumed to be at least 0.5. Default 0.95.\n",
    "        p_value : callable\n",
    "            method for computing the p-value\n",
    "        kwargs is also passed to p_value\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    b : int\n",
    "        confidence bound\n",
    "    alloc : list of ints\n",
    "        allocation that attains the confidence bound\n",
    "    \"\"\"\n",
    "    cl = kwargs.get('cl',0.95)\n",
    "    p_value = kwargs.get('p_value', strat_test_brute)\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    strata = np.array(strata, dtype=int)\n",
    "    sams = np.array(sams, dtype=int)\n",
    "    found = np.array(found, dtype=int)\n",
    "    assert alternative in ['lower', 'upper'], f'alternative {alternative} not implemented'    \n",
    "    if alternative == 'upper':  # interchange good and bad\n",
    "        compl = sams-found      # bad items found\n",
    "        kwargs_c = kwargs.copy()\n",
    "        kwargs_c['alternative'] = 'lower'\n",
    "        cb, alloc_c = strat_ci_bisect(strata, sams, compl, **kwargs_c)\n",
    "        b = np.sum(strata) - cb    # good from bad\n",
    "        alloc = strata-np.array(alloc_c, dtype=int)\n",
    "    else:\n",
    "        cl_sidak = math.pow(cl, 1/len(strata))  # Šidák adjustment\n",
    "        tail = 1-cl\n",
    "        a = sum((hypergeom_conf_interval( \\\n",
    "                sams[s], found[s], strata[s], cl=cl_sidak, alternative=\"lower\")[0] \\\n",
    "                for s in range(len(strata)))) # Šidák should give a lower bound\n",
    "        b = int(np.sum(np.array(strata)*np.array(found)/np.array(sams)))-1 # expected good\n",
    "        p_a, alloc_a = p_value(strata, sams, found, a, alternative=alternative)\n",
    "        p_b, alloc = p_value(strata, sams, found, b, alternative=alternative)\n",
    "        tot_found = np.sum(found)\n",
    "        while p_a > tail and a > tot_found:\n",
    "            a = math.floor(a/2)\n",
    "            p_a, alloc_a = p_value(strata, sams, found, a, **kwargs)\n",
    "        if p_a > tail:\n",
    "            b = a\n",
    "            alloc = alloc_a\n",
    "        else:\n",
    "            while b-a > 1:\n",
    "                c = int((a+b)/2)\n",
    "                p_c, alloc_c = p_value(strata, sams, found, c, **kwargs)\n",
    "                if p_c > tail:\n",
    "                    b, p_b, alloc = c, p_c, alloc_c\n",
    "                elif p_c < tail:\n",
    "                    a, p_a, alloc_a = c, p_c, alloc_c\n",
    "                elif p_c == tail:\n",
    "                    b, p_b, alloc = c, p_c, alloc_c\n",
    "                    break\n",
    "    return b, list(alloc)\n",
    "\n",
    "def strat_ci_search(strata, sams, found, **kwargs):\n",
    "    \"\"\"\n",
    "    Confidence bound on the number of ones in a stratified population,\n",
    "    based on a stratified random sample (without replacement) from\n",
    "    the population.\n",
    "        \n",
    "    If alternative=='lower', finds an upper confidence bound.\n",
    "    If alternative=='upper', finds a lower confidence bound.\n",
    "    \n",
    "    Searches for the allocation of items that attains the confidence bound\n",
    "    by increasing the number of ones from the minimum consistent\n",
    "    with the data (total found in the sample) until the P-value is greater\n",
    "    than 1-cl.\n",
    "    \n",
    "    Uses the fast method for finding the maximum P-value for Fisher's combining function\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes in the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    kwargs : dict\n",
    "        alternative : string {'lower', 'upper'} Default 'lower'\n",
    "            if alternative=='lower', finds an upper confidence bound.\n",
    "            if alternative=='upper', finds a lower confidence bound.\n",
    "            While this is not mnemonic, it corresponds to the sidedness of the tests\n",
    "            that are inverted to get the confidence bound.\n",
    "        cl : float Default 0.95\n",
    "            confidence level. Assumed to be at least 50%.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    cb : int\n",
    "        confidence bound\n",
    "    alloc : list of ints\n",
    "        allocation that attains the confidence bound (give or take one item)\n",
    "    \"\"\"\n",
    "    cl = kwargs.get('cl',0.95)\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower', 'upper'], f'alternative {alternative} not implemented'\n",
    "    strata = np.array(strata, dtype=int)\n",
    "    sams = np.array(sams, dtype=int)\n",
    "    found = np.array(found, dtype=int)\n",
    "    if alternative == 'upper':  # interchange good and bad\n",
    "        kwargs_c = kwargs.copy()\n",
    "        kwargs_c['alternative'] = 'lower'\n",
    "        compl = sams-found  # bad items found\n",
    "        cb, alloc_c = strat_ci(strata, sams, compl, **kwargs_c)\n",
    "        cb = np.sum(strata) - cb    # good from bad\n",
    "        alloc = strata - alloc_c\n",
    "    else:\n",
    "        cb = int(np.sum(strata*found/sams))-1 # expected good\n",
    "        p_attained, alloc = strat_test(strata, sams, found, cb, alternative=alternative)\n",
    "        while p_attained >= 1-cl:\n",
    "            cb -= 1\n",
    "            p_attained, alloc = strat_test(strata, sams, found, cb, alternative=alternative)\n",
    "        cb += 1\n",
    "        p_attained, alloc = strat_test(strata, sams, found, cb, alternative=alternative)\n",
    "    return cb, list(alloc)\n",
    "\n",
    "def strat_ci(strata, sams, found, **kwargs):\n",
    "    \"\"\"\n",
    "    Confidence bound on the number of ones in a population,\n",
    "    based on a stratified random sample (without replacement) from\n",
    "    the population.\n",
    "    \n",
    "    If alternative=='lower', finds an upper confidence bound.\n",
    "    If alternative=='upper', finds a lower confidence bound.\n",
    "    \n",
    "    Constructs the confidence bound directly by constructing the\n",
    "    allocation of the maximum number of ones that would not be\n",
    "    rejected at (conservative) level 1-cl.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes in the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    kwargs : dict\n",
    "        alternative : string {'lower', 'upper'} default 'lower'\n",
    "            if alternative=='lower', finds an upper confidence bound.\n",
    "            if alternative=='upper', finds a lower confidence bound.\n",
    "            While this is not mnemonic, it corresponds to the sidedness of the tests\n",
    "            that are inverted to get the confidence bound.\n",
    "        cl : float default 0.95\n",
    "            confidence level\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    cb : int\n",
    "        confidence bound\n",
    "    alloc : list of ints\n",
    "        allocation that attains the confidence bound (give or take one item)\n",
    "    \"\"\"\n",
    "    cl = kwargs.get('cl',0.95)\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    strata = np.array(strata, dtype=int)\n",
    "    sams = np.array(sams, dtype=int)\n",
    "    found = np.array(found, dtype=int)\n",
    "    assert alternative in ['lower', 'upper'], f'alternative {alternative} not implemented'\n",
    "    if alternative == 'upper':  # interchange role of good and bad\n",
    "        compl = sams - found  # bad found\n",
    "        kwargs_c = kwargs.copy()\n",
    "        kwargs_c['alternative'] = 'lower'\n",
    "        cb, alloc = strat_ci(strata, sams, compl, **kwargs_c)\n",
    "        alloc = strata - alloc\n",
    "    else:                \n",
    "        threshold = -sp.stats.chi2.ppf(cl, df=2*len(strata))/2\n",
    "        # g is in the confidence set if \n",
    "        #          chi2.sf(-2*log(p), df=2*len(strata)) >= 1-cl\n",
    "        #  i.e.,   -2*log(p) <=  chi2.ppf(cl, df)\n",
    "        #  i.e.,   log(p) >= -chi2.ppf(cl, df)/2\n",
    "        optimal = StratifiedBinary(strata=strata, sams=sams, found=found)\n",
    "        optimal.allocate_first()\n",
    "        while np.sum(optimal.log_p) < threshold:\n",
    "            optimal.allocate_next()\n",
    "        alloc = optimal.alloc\n",
    "    return np.sum(alloc), list(alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# older methods\n",
    "\n",
    "def strat_p_ws(strata, sams, found, hypo, **kwargs):\n",
    "    \"\"\"\n",
    "    Finds Wendell-Schmee P-value for the hypothesized population counts 'hypo' for \n",
    "    simple random samples of sizes 'sams' from strata of sizes 'strata' if \n",
    "    'found' 1s are found in the samples from the strata.\n",
    "        \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes from the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    hypo : list of ints\n",
    "        hypothesized number of ones in the strata\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p : float\n",
    "        tail probability\n",
    "    \"\"\"\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower', 'upper']\n",
    "    if alternative == 'lower':                     # exchange roles of \"good\" and \"bad\"\n",
    "        kwargs_c = kwargs.copy()\n",
    "        kwargs_c['alternative'] = 'upper'\n",
    "        compl = np.array(sams) - np.array(found)   # bad items found \n",
    "        hypo_c = np.array(strata) - np.array(hypo) # total bad items hypothesized\n",
    "        p = strat_p_ws(strata, sams, compl, hypo_c, **kwargs_c)\n",
    "    else:    \n",
    "        p_hat = lambda f, st=strata, sa=sams: np.sum(np.array(st)*np.array(f)/np.array(sa))/np.sum(st) # pooled estimate\n",
    "        p_hat_0 = p_hat(found)\n",
    "        per_strat = np.array(strata)/np.array(sams)/np.sum(strata)\n",
    "        strat_max = np.floor(p_hat_0/per_strat)\n",
    "        lo_t = (t for t in itertools.product(*[range(int(s+1)) for s in strat_max]) \\\n",
    "                    if p_hat(t) <= p_hat_0)\n",
    "        p = sum(np.prod(sp.stats.hypergeom.pmf(t, strata, hypo, sams)) \\\n",
    "                    for t in lo_t)\n",
    "    return p\n",
    "\n",
    "def strat_test_ws(strata, sams, found, good, **kwargs):\n",
    "    \"\"\"\n",
    "    Find p-value of the hypothesis that the number G of \"good\" objects in a \n",
    "    stratified population is less than or equal to good, using a stratified\n",
    "    random sample.\n",
    "    \n",
    "    Assumes that a simple random sample of size sams[s] was drawn from stratum s, \n",
    "    which contains strata[s] objects in all.\n",
    "    \n",
    "    The P-value is the maximum Windell-Schmee P-value over all allocations of \n",
    "    good objects among the strata. The allocations are enumerated using Feller's \n",
    "    \"bars and stars\" construction, constrained to honor the stratum sizes (each \n",
    "    stratum can contain no more \"good\" items than it has items in all, nor fewer \n",
    "    \"good\" items than the sample contains).\n",
    "    \n",
    "    The number of allocations grows combinatorially: there can be as many as\n",
    "    [(#strata + #good items) choose (#strata-1)] allocations, making the brute-force\n",
    "    approach computationally infeasible when the number of strata and/or the number of\n",
    "    good items is large.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    strata : list of ints\n",
    "        sizes of the strata. One int per stratum.\n",
    "    sams : list of ints\n",
    "        the sample sizes from each stratum\n",
    "    found : list of ints\n",
    "        the numbers of \"good\" items found in the samples from the strata\n",
    "    good : int\n",
    "        the hypothesized total number of \"good\" objects in the population\n",
    "    alternative : string {'lower', 'upper'}\n",
    "        test against the alternative that the true value is less than good (lower)\n",
    "        or greater than good (upper)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p : float\n",
    "        maximum combined p-value over all ways of allocating good \"good\" objects\n",
    "        among the strata, honoring the stratum sizes.        \n",
    "    alloc : list\n",
    "        the allocation that attained the maximum p-value\n",
    "    \"\"\"\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower', 'upper']\n",
    "    if alternative == 'lower':                   # exchange roles of \"good\" and \"bad\"\n",
    "        compl = np.array(sams) - np.array(found) # bad items found \n",
    "        bad = np.sum(strata) - good              # total bad items hypothesized\n",
    "        kwargs_c = kwargs.copy()\n",
    "        kwargs_c['alternative'] = 'upper'\n",
    "        res = strat_test_ws(strata, sams, compl, bad, **kwargs_c)\n",
    "        return res[0], list(np.array(strata, dtype=int)-np.array(res[1], dtype=int))        \n",
    "    alloc = found # start with what you see\n",
    "    good = int(good)\n",
    "    if good < np.sum(found):     \n",
    "        p = 0 if alternative == 'lower' else 1 \n",
    "    elif good > np.sum(strata) - np.sum(sams) + np.sum(found):\n",
    "        p = 1 if alternative == 'lower' else 0\n",
    "    else:  # use Feller's \"bars and stars\" enumeration of combinations, constrained\n",
    "        p_hat = lambda f, st=strata, sa=sams: np.sum(np.array(st)*np.array(f)/np.array(sa))/np.sum(st) # pooled estimate\n",
    "        p_hat_0 = p_hat(found)\n",
    "        per_strat = np.array(strata)/np.array(sams)/np.sum(strata)\n",
    "        strat_max = np.floor(p_hat_0/per_strat)\n",
    "        p = 0   # initial value for the max\n",
    "        n_strata = len(strata)\n",
    "        parts = sp.special.binom(good+n_strata-1, n_strata-1)\n",
    "        for part in bars_stars(strata, found, good):\n",
    "            lo_t = (t for t in itertools.product(*[range(int(s+1)) for s in strat_max]) \\\n",
    "                    if p_hat(t) <= p_hat_0)\n",
    "            p_new = 0\n",
    "            for t in lo_t:\n",
    "                p_temp = 1\n",
    "                for s in range(len(strata)):\n",
    "                    p_temp *= sp.stats.hypergeom.pmf(t[s], strata[s], part[s], sams[s])\n",
    "                p_new += p_temp\n",
    "            if p_new > p:\n",
    "                alloc = part\n",
    "                p = p_new\n",
    "    return p, list(alloc)\n",
    "\n",
    "def strat_ci_wright(strata, sams, found, **kwargs):\n",
    "    \"\"\"\n",
    "    Confidence bound on the number of ones in a stratified population,\n",
    "    based on a stratified random sample (without replacement) from\n",
    "    the population.\n",
    "    \n",
    "    If alternative=='lower', finds an upper confidence bound.\n",
    "    If alternative=='upper', finds a lower confidence bound.\n",
    "    \n",
    "    Constructs the confidence bound by finding Šidák multiplicity-adjusted\n",
    "    joint lower confidence bounds for the number of ones in each stratum.\n",
    "    \n",
    "    This approach is mentioned in Wright, 1991.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    strata : list of ints\n",
    "        stratum sizes\n",
    "    sams : list of ints\n",
    "        sample sizes in the strata\n",
    "    found : list of ints\n",
    "        number of ones found in each stratum in each sample\n",
    "    alternative : string {'lower', 'upper'}\n",
    "        if alternative=='lower', finds an upper confidence bound.\n",
    "        if alternative=='upper', finds a lower confidence bound.\n",
    "        While this is not mnemonic, it corresponds to the sidedness of the tests\n",
    "        that are inverted to get the confidence bound.\n",
    "    cl : float\n",
    "        confidence level\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    cb : int\n",
    "        confidence bound\n",
    "    \"\"\"\n",
    "    alternative = kwargs.get('alternative','lower')\n",
    "    assert alternative in ['lower', 'upper']\n",
    "    inx = 0 if alternative == 'lower' else 1\n",
    "    cl = kwargs.get('cl',0.95)\n",
    "    cl_sidak = math.pow(cl, 1/len(strata))  # Šidák-adjusted confidence level per stratum\n",
    "    cb = sum((hypergeom_conf_interval(\n",
    "                sams[s], found[s], strata[s], cl=cl_sidak, alternative=alternative)[inx] \n",
    "                for s in range(len(strata))))\n",
    "    return cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_strat_test(verbose = False):\n",
    "    strata = [[10, 20, 30, 40], [20, 20, 20]]\n",
    "    sams = [[2, 3, 4, 5], [5, 5, 10]]\n",
    "    found = [[1, 2, 3, 4], [0, 3, 2]]\n",
    "    for i in range(len(strata)):\n",
    "        compl = np.array(sams[i]) - np.array(found[i])\n",
    "        for j in list(range(4, 20)) + [60]:\n",
    "            for alternative in ['lower', 'upper']:\n",
    "                if verbose:\n",
    "                    print(f'{i=} {j=} {alternative=}')\n",
    "                p_exact = strat_test_brute(strata[i], sams[i], found[i], j, alternative=alternative)\n",
    "                p_exact_c = strat_test_brute(strata[i], sams[i], compl, j, alternative=alternative)\n",
    "                p_fast = strat_test(strata[i], sams[i], found[i], j, alternative=alternative)\n",
    "                p_fast_c  = strat_test(strata[i], sams[i], compl, j, alternative=alternative)\n",
    "                np.testing.assert_allclose(p_exact[0], p_fast[0])\n",
    "                np.testing.assert_allclose(p_exact_c[0], p_fast_c[0])\n",
    "\n",
    "def test_strat_ci(verbose = False):\n",
    "    strata = [[10, 20], [10, 20, 30, 40], [10, 20, 20, 30]]\n",
    "    sams = [[5, 5], [2, 3, 4, 5], [2, 4, 5, 6]]\n",
    "    found = [[2, 2], [1, 2, 3, 4], [0, 1, 2, 3]]\n",
    "    for i in range(len(strata)):\n",
    "        for alternative in ['lower','upper']:\n",
    "            brute = strat_ci_bisect(strata[i], sams[i], found[i], alternative=alternative)\n",
    "            fast = strat_ci(strata[i], sams[i], found[i], alternative=alternative)\n",
    "            fast_s = strat_ci_search(strata[i], sams[i], found[i], alternative=alternative)\n",
    "            if verbose:\n",
    "                print(f'{i}-{alternative}')\n",
    "                print(f'i:{i} brute:{brute[0]} fast:{fast[0]} fast_s:{fast_s[0]}\\nbest_brute: {brute[1]} best_fast:{fast[1]} best_fast_s: {fast_s[1]}')\n",
    "            np.testing.assert_allclose(brute[0], fast[0])\n",
    "            np.testing.assert_allclose(brute[0], fast_s[0])\n",
    "            np.testing.assert_allclose(brute[1], fast[1])\n",
    "            np.testing.assert_allclose(brute[1], fast_s[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strat_test(verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strat_ci(verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Wendell & Schmee (1996) $P$-values and upper confidence bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_strat_test_ws(verbose = False):\n",
    "    strata = [[10, 20, 30, 40], [20, 20, 20]]\n",
    "    sams = [[2, 3, 4, 5], [5, 5, 10]]\n",
    "    found = [[1, 2, 3, 4], [0, 3, 2]]\n",
    "    for i in range(len(strata)):\n",
    "        compl = np.array(sams[i]) - np.array(found[i])\n",
    "        alternative = 'upper'\n",
    "        for j in list(range(4, 20)) + [60]:\n",
    "            if verbose:\n",
    "                print(f'{i=} {j=} {alternative=}')\n",
    "            p_ws = strat_test_ws(strata[i], sams[i], found[i], j, alternative=alternative)\n",
    "            p_ws_c = strat_test_ws(strata[i], sams[i], compl, j, alternative=alternative)\n",
    "            p_fast = strat_test(strata[i], sams[i], found[i], j, alternative=alternative)\n",
    "            p_fast_c = strat_test(strata[i], sams[i], compl, j, alternative=alternative)\n",
    "            print(f'ws: {p_ws[0]} ws_c: {p_ws_c[0]} best: {p_ws[1]} best_c: {p_ws_c[1]}')\n",
    "            print(f'fast: {p_fast[0]} fast_c: {p_fast_c[0]} best: {p_fast[1]} best_c: {p_fast_c[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ws: 1 ws_c: 1.0000000000000002 best: [1, 2, 3, 4] best_c: [1, 1, 1, 1]\n",
      "fast: 1 fast_c: 1 best: None best_c: [1, 1, 1, 1]\n",
      "ws: 1 ws_c: 0.9999444444444435 best: [1, 2, 3, 4] best_c: [2, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.9999999988567956 best: None best_c: [1, 1, 1, 2]\n",
      "ws: 1 ws_c: 0.999833333333334 best: [1, 2, 3, 4] best_c: [3, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.9999999789845687 best: None best_c: [1, 1, 2, 2]\n",
      "ws: 1 ws_c: 0.9996666666666645 best: [1, 2, 3, 4] best_c: [4, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.9999998660332918 best: None best_c: [1, 2, 2, 2]\n",
      "ws: 1 ws_c: 0.999444444444445 best: [1, 2, 3, 4] best_c: [5, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.9999992860845038 best: None best_c: [2, 2, 2, 2]\n",
      "ws: 1 ws_c: 0.9991666666666645 best: [1, 2, 3, 4] best_c: [6, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.999997522402079 best: None best_c: [2, 2, 2, 3]\n",
      "ws: 0.9999999999999987 ws_c: 0.9988333333333342 best: [1, 2, 3, 4] best_c: [7, 1, 1, 1]\n",
      "fast: 1 fast_c: 0.9999931894258484 best: [1, 2, 3, 4] best_c: [2, 2, 3, 3]\n",
      "ws: 0.9999999999810854 ws_c: 0.9984444444444441 best: [2, 2, 3, 4] best_c: [8, 1, 1, 1]\n",
      "fast: 1.0 fast_c: 0.999982932037665 best: [1, 2, 3, 5] best_c: [2, 3, 3, 3]\n",
      "ws: 0.9999999999432605 ws_c: 0.9980000000000002 best: [3, 2, 3, 4] best_c: [9, 1, 1, 1]\n",
      "fast: 1.0 fast_c: 0.9999614134317659 best: [1, 2, 3, 6] best_c: [2, 3, 3, 4]\n",
      "ws: 0.9999999998865183 ws_c: 0.9974999999999993 best: [4, 2, 3, 4] best_c: [10, 1, 1, 1]\n",
      "fast: 1.0 fast_c: 0.9999200792544627 best: [1, 2, 3, 7] best_c: [2, 3, 4, 4]\n",
      "ws: 0.9999999998108691 ws_c: 0.9921367521367547 best: [5, 2, 3, 4] best_c: [10, 1, 1, 2]\n",
      "fast: 1.0 fast_c: 0.9998400267645521 best: [1, 2, 4, 7] best_c: [2, 3, 4, 5]\n",
      "ws: 0.9999999997163019 ws_c: 0.9836369770580294 best: [6, 2, 3, 4] best_c: [10, 1, 1, 3]\n",
      "fast: 1.0 fast_c: 0.9997087317388961 best: [1, 2, 4, 8] best_c: [2, 4, 4, 5]\n",
      "ws: 0.9999999996028268 ws_c: 0.9718094612831454 best: [7, 2, 3, 4] best_c: [10, 1, 1, 4]\n",
      "fast: 0.9999999999999999 fast_c: 0.9995066807966366 best: [1, 2, 4, 9] best_c: [3, 4, 4, 5]\n",
      "ws: 0.9999999994704348 ws_c: 0.9565397887766312 best: [8, 2, 3, 4] best_c: [10, 1, 1, 5]\n",
      "fast: 0.9999999999999992 fast_c: 0.9992064404749985 best: [1, 2, 5, 9] best_c: [3, 4, 5, 5]\n",
      "ws: 0.9999999993191306 ws_c: 0.9377850725219145 best: [9, 2, 3, 4] best_c: [10, 1, 1, 6]\n",
      "fast: 0.9999999999999958 fast_c: 0.9987578291088032 best: [1, 2, 5, 10] best_c: [3, 4, 5, 6]\n",
      "ws: 0.9999999991489137 ws_c: 0.915568686095002 best: [10, 2, 3, 4] best_c: [10, 1, 1, 7]\n",
      "fast: 0.9999999999999745 fast_c: 0.9980704752694506 best: [1, 2, 5, 11] best_c: [3, 4, 6, 6]\n",
      "ws: 0.9809423942999241 ws_c: 0.005696151392875078 best: [10, 2, 8, 40] best_c: [7, 13, 18, 22]\n",
      "fast: 0.9984282967061362 fast_c: 0.16107135673314996 best: [2, 10, 19, 29] best_c: [7, 12, 18, 23]\n",
      "ws: 1 ws_c: 1 best: [0, 3, 2] best_c: [5, 2, 8]\n",
      "fast: 1 fast_c: 1 best: None best_c: None\n",
      "ws: 0.9999999999999991 ws_c: 1 best: [0, 3, 2] best_c: [5, 2, 8]\n",
      "fast: 1 fast_c: 1 best: [0, 3, 2] best_c: None\n",
      "ws: 0.9992124273532111 ws_c: 1 best: [0, 4, 2] best_c: [5, 2, 8]\n",
      "fast: 0.9999999998166784 fast_c: 1 best: [0, 4, 2] best_c: None\n",
      "ws: 0.9974471783173097 ws_c: 1 best: [0, 3, 4] best_c: [5, 2, 8]\n",
      "fast: 0.9999999802958488 fast_c: 1 best: [0, 5, 2] best_c: None\n",
      "ws: 0.9934753679865279 ws_c: 1 best: [0, 3, 5] best_c: [5, 2, 8]\n",
      "fast: 0.9999995445513106 fast_c: 1 best: [0, 6, 2] best_c: None\n",
      "ws: 0.9847170170007047 ws_c: 1 best: [0, 3, 6] best_c: [5, 2, 8]\n",
      "fast: 0.9999950631446368 fast_c: 1 best: [0, 7, 2] best_c: None\n",
      "ws: 0.9690334582586491 ws_c: 1 best: [0, 3, 7] best_c: [5, 2, 8]\n",
      "fast: 0.9999663745711513 fast_c: 1 best: [0, 8, 2] best_c: None\n",
      "ws: 0.9446636208286848 ws_c: 1 best: [0, 3, 8] best_c: [5, 2, 8]\n",
      "fast: 0.9998332328548011 fast_c: 1 best: [0, 9, 2] best_c: None\n",
      "ws: 0.9096534575901524 ws_c: 1 best: [0, 3, 9] best_c: [5, 2, 8]\n",
      "fast: 0.9993435952582238 fast_c: 1 best: [0, 10, 2] best_c: None\n",
      "ws: 0.8615152873035397 ws_c: 1 best: [0, 3, 10] best_c: [5, 2, 8]\n",
      "fast: 0.9978334049132793 fast_c: 1 best: [0, 11, 2] best_c: None\n",
      "ws: 0.7977494641581321 ws_c: 1 best: [0, 3, 11] best_c: [5, 2, 8]\n",
      "fast: 0.9939841431087776 fast_c: 1 best: [0, 11, 3] best_c: None\n",
      "ws: 0.7172269504435058 ws_c: 0.9999999999999961 best: [0, 3, 12] best_c: [5, 2, 8]\n",
      "fast: 0.9872797224870071 fast_c: 1 best: [0, 12, 3] best_c: [5, 2, 8]\n",
      "ws: 0.6217241051545268 ws_c: 0.9999999999999971 best: [0, 3, 13] best_c: [6, 2, 8]\n",
      "fast: 0.9736250862338577 fast_c: 1.0 best: [0, 13, 3] best_c: [6, 2, 8]\n",
      "ws: 0.5199586389671542 ws_c: 0.999999999999997 best: [2, 3, 12] best_c: [7, 2, 8]\n",
      "fast: 0.946965994360294 fast_c: 1.0 best: [0, 14, 3] best_c: [7, 2, 8]\n",
      "ws: 0.43870488123980333 ws_c: 0.9999999999999979 best: [7, 7, 4] best_c: [8, 2, 8]\n",
      "fast: 0.9062534551334417 fast_c: 1.0 best: [0, 14, 4] best_c: [8, 2, 8]\n",
      "ws: 0.37086615075619256 ws_c: 0.9999999999999977 best: [8, 7, 4] best_c: [9, 2, 8]\n",
      "fast: 0.8457350377876189 fast_c: 1.0 best: [0, 15, 4] best_c: [9, 2, 8]\n",
      "ws: 0 ws_c: 0 best: [0, 3, 2] best_c: [5, 2, 8]\n",
      "fast: 0 fast_c: 0 best: None best_c: None\n"
     ]
    }
   ],
   "source": [
    "# time-consuming!\n",
    "test_strat_test_ws(verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.067081 (0.23485578913926813, [2, 8]) (0.06708103400254271, [2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Wendell & Schmee lead example, p. 827\n",
    "strata = [100, 100]\n",
    "sams = [60, 40]\n",
    "found = [1, 1]\n",
    "good = 10 \n",
    "p = .067081\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative),\\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01194 (0.06481873546070493, [10, 5]) (0.011942274979969247, [10, 5])\n"
     ]
    }
   ],
   "source": [
    "# Table 2, row 1\n",
    "strata = [200, 100]\n",
    "sams = [50, 25] \n",
    "found = [0,0]\n",
    "good = 15 \n",
    "p = .01194\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative), \\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07232 (0.26226855041248087, [15, 0]) (0.07231577125487271, [15, 0])\n"
     ]
    }
   ],
   "source": [
    "# Table 2, row 2\n",
    "strata = [200, 100]\n",
    "sams = [50,50] \n",
    "found = [1,0]\n",
    "good = 15 \n",
    "p = .07232\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative), \\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09958 (0.3292825209349363, [150, 0]) (0.09957652360481824, [150, 0])\n"
     ]
    }
   ],
   "source": [
    "# Table 2, row 3\n",
    "strata = [2000, 1000]\n",
    "sams = [50,50]\n",
    "found = [1,0]\n",
    "good = 150 \n",
    "p = .09958\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative), \\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03775 (0.349110173834897, [25, 5, 0]) (0.037749475267350535, [24, 6, 0])\n"
     ]
    }
   ],
   "source": [
    "# Table 2, row 9. \n",
    "strata = [300, 200, 100]\n",
    "sams = [50,50,50]\n",
    "found = [1, 1, 0]\n",
    "good = 30 \n",
    "p = .03775\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative),\\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04902 (0.4006985692204492, [247, 53, 0]) (0.04902098371080246, [228, 72, 0])\n"
     ]
    }
   ],
   "source": [
    "# Table 2, row 10. \n",
    "strata = [3000, 2000, 1000]\n",
    "sams = [50,50,50]\n",
    "found = [1, 1, 0]\n",
    "good = 300 \n",
    "p = .04902\n",
    "alternative = 'upper'\n",
    "print(p, strat_test(strata, sams, found, good, alternative=alternative),\\\n",
    "      strat_test_ws(strata, sams, found, good, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.25567352840348917, [38, 12, 0]) (0.02767568706972813, [28, 21, 1])\n"
     ]
    }
   ],
   "source": [
    "# compare with Wendell & Schmee's R code.\n",
    "# \n",
    "# > pmax.function(c(500,300,200),c(75,50,25),c(2,1,0),50)\n",
    "#            [,1] [,2] [,3] [,4]\n",
    "# [1,] 0.02767569   28   21    1\n",
    "#\n",
    "# indicating a maximum p-value of 0.02768 occurring under the null of 50 errors\n",
    "# with those errors distributed as (28,21,1).\n",
    "print(strat_test([500,300,200],[75,50,25],[2,1,0],50, alternative='upper'),\\\n",
    "      strat_test_ws([500,300,200],[75,50,25],[2,1,0],50, alternative='upper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 (10, [6, 4]) (16, [11, 5]) 23\n"
     ]
    }
   ],
   "source": [
    "# Table 3, Row 1\n",
    "strata = [200, 100]\n",
    "sams = [50,25]\n",
    "found = [0, 0]\n",
    "ub = 10\n",
    "alternative = 'upper'\n",
    "print(ub,\\\n",
    "      strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws),\\\n",
    "      strat_ci(strata, sams, found, alternative=alternative),\\\n",
    "      strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599 (599, [2, 597]) (701, [124, 577]) 876\n"
     ]
    }
   ],
   "source": [
    "# Table 3, Row 7.\n",
    "strata = [5000, 5000]\n",
    "sams = [100,50]\n",
    "found = [2,1] \n",
    "ub = 599\n",
    "alternative = 'upper'\n",
    "print(ub,\\\n",
    "      strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws),\\\n",
    "      strat_ci(strata, sams, found, alternative=alternative),\\\n",
    "      strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5b981f5df55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0malternative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upper'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m print(ub,\\\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mstrat_ci_bisect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malternative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrat_test_ws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mstrat_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malternative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       strat_ci_wright(strata, sams, found, alternative=alternative))\n",
      "\u001b[0;32m<ipython-input-4-9aa1d3efc969>\u001b[0m in \u001b[0;36mstrat_ci_bisect\u001b[0;34m(strata, sams, found, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mkwargs_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mkwargs_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alternative'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lower'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alloc_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrat_ci_bisect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcb\u001b[0m    \u001b[0;31m# good from bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mbest_alloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrata\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_alloc_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9aa1d3efc969>\u001b[0m in \u001b[0;36mstrat_ci_bisect\u001b[0;34m(strata, sams, found, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mp_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alloc_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp_c\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alloc_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4de1f2769c99>\u001b[0m in \u001b[0;36mstrat_test_ws\u001b[0;34m(strata, sams, found, good, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mkwargs_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mkwargs_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alternative'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upper'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrat_test_ws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mbest_alloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;31m# start with what you see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4de1f2769c99>\u001b[0m in \u001b[0;36mstrat_test_ws\u001b[0;34m(strata, sams, found, good, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mp_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mp_temp\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypergeom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mp_new\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp_new\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mpmf\u001b[0;34m(self, k, *args, **kwds)\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m             \u001b[0mplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_discrete_distns.py\u001b[0m in \u001b[0;36m_pmf\u001b[0;34m(self, k, M, n, N)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# same as the following but numerically more precise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# return comb(good, k) * comb(bad, N-k) / comb(tot, N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logpmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_discrete_distns.py\u001b[0m in \u001b[0;36m_logpmf\u001b[0;34m(self, k, M, n, N)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mtot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         result = (betaln(good+1, 1) + betaln(bad+1, 1) + betaln(tot-N+1, N+1) -\n\u001b[0m\u001b[1;32m    464\u001b[0m                   \u001b[0mbetaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbetaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                   betaln(tot+1, 1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Table 3, Row 10. WARNING: LONG RUN TIME\n",
    "strata = [3000, 2000, 1000] \n",
    "sams = [50,50,50]\n",
    "found = [1, 1, 0]\n",
    "ub = 298\n",
    "alternative = 'upper'\n",
    "print(ub,\\\n",
    "      strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws),\\\n",
    "      strat_ci(strata, sams, found, alternative=alternative),\\\n",
    "      strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3, last row. LONG RUN TIME\n",
    "strata = [5000, 3000, 2000]\n",
    "sams = [75,50,25]\n",
    "found = [2, 1, 0] \n",
    "ub = 471\n",
    "alternative = 'upper'\n",
    "print(ub, strat_ci(strata, sams, found, alternative=alternative), \\\n",
    "     strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws), \\\n",
    "     strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is the new method sharper than Wendell & Schmee?\n",
    "\n",
    "In general, when there is large heterogeneity of rates across strata.\n",
    "\n",
    "\n",
    "strata = [100, 100]\n",
    "sams = [30,30]\n",
    "found = [15,0] \n",
    "(68, [34, 34]) (68, [67, 1]) 74\n",
    "\n",
    "strata = [100, 100]\n",
    "sams = [30,30]\n",
    "found = [20,0] \n",
    "(85, [43, 42]) (83, [79, 4]) 89\n",
    "\n",
    "strata = [100, 100, 100]\n",
    "sams = [25, 25, 25]\n",
    "found = [20, 0, 0] \n",
    "(105, [35, 35, 35]) (102, [88, 7, 7]) 118\n",
    "\n",
    "strata = [100, 100, 100, 100]\n",
    "sams = [25, 25, 25, 25]\n",
    "found = [10, 0, 0, 0] \n",
    "\n",
    "strata = [100, 100, 100, 100]\n",
    "sams = [25,25,25,25]\n",
    "found = [20,0,0,0] \n",
    "Ran for a week without completing. Fast method took under a second.\n",
    "---- (107, [88, 6, 6, 7]) 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, [88, 6, 6, 7]) 131\n"
     ]
    }
   ],
   "source": [
    "strata = [100, 100, 100, 100]\n",
    "sams = [25,25,25,25]\n",
    "found = [20,0,0,0] \n",
    "alternative = 'upper'\n",
    "print(\\\n",
    "#      strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws),\\\n",
    "      strat_ci(strata, sams, found, alternative=alternative),\\\n",
    "      strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata = [100, 100, 100]\n",
    "sams = [25, 25, 25]\n",
    "found = [10, 0, 0]\n",
    "alternative = 'upper'\n",
    "print(\\\n",
    "      strat_ci_bisect(strata, sams, found, alternative=alternative, p_value=strat_test_ws),\\\n",
    "      strat_ci(strata, sams, found, alternative=alternative),\\\n",
    "      strat_ci_wright(strata, sams, found, alternative=alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 1.0\n",
      "102 102 1.0\n",
      "202 202 1.0\n",
      "302 302 1.0\n",
      "402 402 1.0\n",
      "502 502 1.0\n",
      "602 602 1.0\n",
      "702 702 1.0\n",
      "802 802 1.0\n",
      "902 901 0.9988913525498891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test empirical coverage\n",
    "reps = 1000\n",
    "cl = 0.95\n",
    "alternative = 'upper'\n",
    "strata = [5000, 3000, 2000]\n",
    "sams = [75,50,25]\n",
    "good = [100, 100, 500]\n",
    "g = np.sum(good)\n",
    "cover = 0\n",
    "verb = False\n",
    "for i in range(reps):\n",
    "    found = sp.stats.hypergeom.rvs(strata, good, sams)\n",
    "    ub = strat_ci(strata, sams, found, alternative=alternative, cl=cl)\n",
    "    if verb: \n",
    "        print(\"f: {} ub: {} best: {}\".format(found, ub[0], ub[1]))\n",
    "    cover = cover+1 if ub[0] >= g else cover\n",
    "    if i % 100 == 1:\n",
    "        print(i+1, cover, cover/(i+1))\n",
    "cover/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
